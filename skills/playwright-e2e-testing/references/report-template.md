# E2E Test Report Template

Template structure for comprehensive test reports.

## Report Structure

```markdown
# [✅/❌] E2E Test Report: [Test Name]

**Status:** PASSED/FAILED
**Date:** [ISO timestamp]
**URL:** [Application URL]
**Duration:** [X.XX]s

---

## Test Summary

- Console Errors: [count]
- Network Failures: [count]
- Steps Completed: [X of Y]

**Failure Reason:** [If failed, explain why]

## Test Steps

1. [Step 1 description]
   - Action: [What was done]
   - Expected: [What should happen]
   - Actual: [What happened]
   - Status: ✅/❌

2. [Step 2 description]
   - Action: [What was done]
   - Expected: [What should happen]
   - Actual: [What happened]
   - Status: ✅/❌

[Continue for all steps...]

## Console Logs

### Errors
1. `[Error message]`
2. `[Error message]`

### Warnings
1. `[Warning message]`

## Network Requests

| Method | URL | Status | Type |
|--------|-----|--------|------|
| GET | /api/users | 200 | xhr |
| POST | /api/login | 200 | xhr |

## Screenshots

### Initial State
![Initial State](path/to/initial.png)

### Step 2 - After Login
![After Login](path/to/after-login.png)

### Final State
![Final State](path/to/final.png)

## Accessibility Snapshots

- Initial State: [initial-state.md](path/to/initial-state.md)
- Final State: [final-state.md](path/to/final-state.md)

## Verification Criteria

✅/❌ Expected text "[text]" is present
✅/❌ No console errors
✅/❌ API call [method] [endpoint] returned [expected status]
✅/❌ Element [description] is visible
✅/❌ Navigation to [URL] succeeded

## Recommendations

[For failures, provide recommendations]

- [Recommendation 1]
- [Recommendation 2]
- [Recommendation 3]

## Test Metadata

- Browser: Chromium
- Viewport: 1920x1080
- Test Environment: [local/staging/production]
- Test Data: [description of test data used]

---

**Generated by:** Playwright E2E Testing Skill
**Report Version:** 1.0
```

## Section Guidelines

### Test Summary
- Provide high-level metrics
- Count errors and failures
- Track step completion
- Include duration for performance tracking

### Test Steps
- List all planned steps
- Mark each as passed/failed
- Include expected vs actual for failures
- Use clear action descriptions

### Console Logs
- Separate errors and warnings
- Include full error messages
- Group related errors
- Note timing if relevant

### Network Requests
- Show all API calls
- Highlight failures (4xx, 5xx)
- Include request type
- Track response times for performance tests

### Screenshots
- Use descriptive captions
- Show before/after states
- Capture error states
- Include intermediate steps for complex flows

### Verification Criteria
- List explicit success criteria
- Mark each as passed/failed
- Be specific (not "page loads" but "Welcome text visible")
- Include all assertions

### Recommendations
- Only for failed tests
- Be actionable and specific
- Prioritize by impact
- Reference evidence (console logs, network requests)

## Report Variants

### Quick Report (Passed Test)
Minimal report for successful tests:
```markdown
# ✅ Login Flow Test

**Status:** PASSED
**Duration:** 3.2s
**URL:** http://localhost:3000/login

**Verification:**
✅ Login successful
✅ No console errors
✅ API calls succeeded

**Evidence:** [initial.png](path), [final.png](path)
```

### Detailed Report (Failed Test)
Comprehensive report for failures:
```markdown
[Include all sections above]
[Emphasize failure analysis]
[Provide detailed recommendations]
```

### Performance Report
Focus on timing and optimization:
```markdown
[Standard sections plus:]

## Performance Metrics

| Metric | Value | Threshold | Status |
|--------|-------|-----------|--------|
| Page Load | 1.2s | <2s | ✅ |
| First API Call | 340ms | <500ms | ✅ |
| Total Requests | 15 | <20 | ✅ |
| Bundle Size | 450KB | <500KB | ✅ |
```

### Regression Report
Compare current vs baseline:
```markdown
[Standard sections plus:]

## Regression Analysis

| Test Step | Baseline | Current | Change |
|-----------|----------|---------|--------|
| Login | ✅ | ✅ | No change |
| Dashboard Load | ✅ | ❌ | REGRESSION |
| API Response | 200 | 500 | REGRESSION |
```

## Automation

Use `scripts/generate_test_report.py` to generate reports automatically:

```bash
python scripts/generate_test_report.py \
  --test-name "Login Flow" \
  --url "http://localhost:3000" \
  --initial-snapshot snapshots/initial.md \
  --final-snapshot snapshots/final.md \
  --screenshots screenshots/initial.png,screenshots/final.png \
  --console-logs logs/console.json \
  --network-requests logs/network.json \
  --status "passed" \
  --duration 3.2 \
  --output reports/login-test.md
```

## Best Practices

1. **Be Specific** - "Login button clicked" not "Action performed"
2. **Include Context** - Show before/after states
3. **Reference Evidence** - Link to screenshots/logs
4. **Be Actionable** - Recommendations should be implementable
5. **Be Consistent** - Use template structure for all tests
6. **Version Control** - Commit reports for historical tracking
7. **Automate** - Use scripts to generate reports
8. **Share** - Reports should be readable by non-technical stakeholders
